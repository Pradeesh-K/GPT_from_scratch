{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ed25172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT\n",
    "# a sequence of tokens, how they are sequenced, we give start of sequence the model continues\n",
    "# Generatively Pre-trained Transformer\n",
    "# Character level language model\n",
    "# Tiny shakesphere - concatenated work of all shakesphere in text filter\n",
    "# We model how charcters follow if given context\n",
    "# Output is a shakesphere like text\n",
    "# NanoGPT . train GPT with any text 124 million params - 38 hours training time in a single 8xA100 40GB Node\n",
    "#  8xA100 40GB - One machine with 8 NVIDIA A100 GPUs, each with 40 GB of VRAM, connected via NVLink or PCIe for multi-GPU training\n",
    "# using OpenWebText data \n",
    "# OpenwebText has 38GB of text data (40GB using SI units) from 8,013,769 documents\n",
    "# train.py is 300 line training loop\n",
    "# model.py a 300 line GPT model definition\n",
    "# A multilayer perceptron is a fully connected feedforward net with at least three layers (input, hidden and output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "775d5854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
    "# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b6de77f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it in to inspect it\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "108ff6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  1115394, type of dataset: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"length of dataset in characters:  {len(text)}, type of dataset: {type(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "46e79616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "set_of_text = set(text) # {'e', 'X', 'y', 'N', 'J', '3', 'o', 'w', 'b', 'U', '\n",
    "list_of_text = list(set_of_text) # ['e', 'X', 'y', 'N', 'J', '3', 'o', 'w', 'b', 'U', \n",
    "print(chars) # ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size) # entire set of characters - all possible characters the model can see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3f0187eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n",
      "{0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}\n",
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "# tokenize - convert raw text to sequence of numbers based on vocabulary. this is char level tokenization. all chars\n",
    "# openi - bite pair encoding . 50000 tokens- hii there - integers between 0 to 50000. sub word encoding. short seq int with large vocab or large seq integer with small vocab\n",
    "# create a mapping from characters to integers\n",
    "# enumerate(iterable, start=0)\n",
    "# Using the enumerate() function is useful from the standpoint of its memory and computing efficiency compared to using for-loops since it returns the index and the corresponding item at one go.\n",
    "# this function assigns a count incrementing by 1 to each item of an iterable and helps us track iterations while looping through that object\n",
    "stoi = { ch:i for i,ch in enumerate(chars) } #  enumerate(chars). Lookup table Each char gets a number {'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4\n",
    "itos = { i:ch for i,ch in enumerate(chars) } #. Reverse lookup table of itos {0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\" .. Each number gets a character\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers. For each char, outputs the corresponding number\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string. For each number outputs the correponding character and then combined as a string\n",
    "print(stoi)\n",
    "print(itos)\n",
    "print(encode(\"hii there\")) # list of integers that represent string\n",
    "print(decode(encode(\"hii there\"))) # reverse mapping, decode integers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9c5e14a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long) # text is that massive string, now it outputs a tensor a 1-1 encoding of the characters in text to numbers\n",
    "print(data.shape, data.dtype) # shape is 1 x 1115394 # torch.Size([1115394]) torch.int64\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ae82f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train validation split\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data=data[n:]\n",
    "# we dont feed all at once, we sample random chunks and train on chunks at once\n",
    "# max chunk is blocksize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1ee31158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we dont feed all at once, we sample random chunks and train on chunks at once\n",
    "# max chunk is blocksize \n",
    "block_size = 8\n",
    "train_data[:block_size+1] # tensor([18, 47, 56, 57, 58,  1, 15, 47, 58]). context of 18, 47 56 comes next, 18,47,56 context 57 comes next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a88c3174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target: 47\n",
      "when input is tensor([18, 47]) the target: 56\n",
      "when input is tensor([18, 47, 56]) the target: 57\n",
      "when input is tensor([18, 47, 56, 57]) the target: 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size] # 8 characters\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1] # for 0 to t characters, target is the corresponding t\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")\n",
    "\n",
    "# we could predict from 1 to block size, beyond this we have to truncate\n",
    "# mini batches multiple chunks stacked on top of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e16ba6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "----\n",
      "when input is [24] the target: 43\n",
      "when input is [24, 43] the target: 58\n",
      "when input is [24, 43, 58] the target: 5\n",
      "when input is [24, 43, 58, 5] the target: 57\n",
      "when input is [24, 43, 58, 5, 57] the target: 1\n",
      "when input is [24, 43, 58, 5, 57, 1] the target: 46\n",
      "when input is [24, 43, 58, 5, 57, 1, 46] the target: 43\n",
      "when input is [24, 43, 58, 5, 57, 1, 46, 43] the target: 39\n",
      "when input is [44] the target: 53\n",
      "when input is [44, 53] the target: 56\n",
      "when input is [44, 53, 56] the target: 1\n",
      "when input is [44, 53, 56, 1] the target: 58\n",
      "when input is [44, 53, 56, 1, 58] the target: 46\n",
      "when input is [44, 53, 56, 1, 58, 46] the target: 39\n",
      "when input is [44, 53, 56, 1, 58, 46, 39] the target: 58\n",
      "when input is [44, 53, 56, 1, 58, 46, 39, 58] the target: 1\n",
      "when input is [52] the target: 58\n",
      "when input is [52, 58] the target: 1\n",
      "when input is [52, 58, 1] the target: 58\n",
      "when input is [52, 58, 1, 58] the target: 46\n",
      "when input is [52, 58, 1, 58, 46] the target: 39\n",
      "when input is [52, 58, 1, 58, 46, 39] the target: 58\n",
      "when input is [52, 58, 1, 58, 46, 39, 58] the target: 1\n",
      "when input is [52, 58, 1, 58, 46, 39, 58, 1] the target: 46\n",
      "when input is [25] the target: 17\n",
      "when input is [25, 17] the target: 27\n",
      "when input is [25, 17, 27] the target: 10\n",
      "when input is [25, 17, 27, 10] the target: 0\n",
      "when input is [25, 17, 27, 10, 0] the target: 21\n",
      "when input is [25, 17, 27, 10, 0, 21] the target: 1\n",
      "when input is [25, 17, 27, 10, 0, 21, 1] the target: 54\n",
      "when input is [25, 17, 27, 10, 0, 21, 1, 54] the target: 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337) # seed is set so it is reproducable\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,)) # generate batch size number of random offsets# gets 4 random indices between 0 to len(data) - block_size as we need mini batches too\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix]) # gets 8 chars from indices. stack as rows  4x8 tensor\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])  # gets 8 chars  from index+1\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension # for each mini batch \n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1] # does the context step 0 - 0: 0,1- 1:0,1,2-2\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")\n",
    "# #\n",
    "# target = yb[b, t] → the token the model should predict at this position\n",
    "\n",
    "# Because yb is shifted by 1 from xb, the target is always the next token after the current context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6734f736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before Embedding(65, 65)\n",
      "tensor(5.0364, grad_fn=<NllLossBackward0>)\n",
      "'XAQHukRuaRJKXAYtXzfJ:HEPiu--sDioi;ILCo3pHNTmDwJsfheKRxZCFs\n",
      "lZJ XQc?:s:HEzEnXalEPklcPU cL'DpdLCafBheH\n"
     ]
    }
   ],
   "source": [
    "# Bigram model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size) # a lookup table 65 number of embeddings, and 65 is embedding dim\n",
    "        print(\"before\", self.token_embedding_table)\n",
    "        '''we have 65 possible tokens (chars in dataset)\n",
    "        Each token is mapped to a vector of size 65.\n",
    "        E = [\n",
    "            [e11, e12, ..., e165],   # embedding vector for token 0\n",
    "            [e21, e22, ..., e265],   # embedding vector for token 1\n",
    "            ...\n",
    "            [e651, ..., e6565]       # embedding vector for token 64\n",
    "            ]\n",
    "\n",
    "        '''\n",
    "    def forward(self, idx, targets=None):\n",
    "        #idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) \n",
    "        # the vocab size is 65- all characters of shakesphere. we create a random embedding of 65 x 65 . \n",
    "        # where 65 is vocab size and 65 is the embedding space. They are learnable weights\n",
    "        # During training, they get adjusted so that tokens that appear in similar contexts have similar embeddings.\n",
    "        # The order of tokens will matter downstream when predicting the next token, because the model sees xb[b, :t] as “context”.\n",
    "        # But the embedding of each token by itself does not encode position — it’s just a vector representing that token.\n",
    "        # print(logits)\n",
    "        '''\n",
    "        We have the input as 4 x 8 of the forward encode - and it gives the embedding for each\n",
    "        ''' \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # picks out the row from table B,T,C 4 x 8 x 65\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C ) # we stack the tokens neatly one below another without messing up the order. so we have 32 rows each of 65 numbers as per embedding\n",
    "            targets = targets.view (B*T) # 4 x 8 gives (32,)\n",
    "            loss = F.cross_entropy(logits, targets) # torch wants B x T X C. \n",
    "            # For each row of logits, Treat it as the unnormalized scores for all 65 tokens. Apply softmax internally → get probabilities over 65 classes\n",
    "            # for embeddings of other size 128 dimension etc, we have a linear neural network that projects it back to logits\n",
    "            # self.fc = nn.Linear(embedding_dim, vocab_size)  # 124 → 65\n",
    "            # logits = self.fc(embedding_table[idx])          # shape: (B, T, 65)\n",
    "            # omg that Problem: You cannot feed 124-dimensional embeddings directly to cross-entropy, because cross_entropy expects logits over vocab size (65).\n",
    "            # Solution: add a linear projection: totally solved all my confusion. karpathy basically left this critical step, or he had another video which i \n",
    "            # didnt watch. so basically the embedding is like a input for neural network with its own layers . can be multiple and that outputs the logits and we do \n",
    "            # softmax to get max probability of token and compare that to target. \n",
    "            # solved. all clear now only tell me in this case the input is independently used to generate output token by token \n",
    "            # 24, 43, 58,  5, 57,  1, 46, 43 - are we brute forcing it. like for ex  we use embedding of 58 only to generate the output and not 24,43,58\n",
    "            # The model is very simple: it only looks at the current token to predict the next token\n",
    "            # Input 24 → embedding → predicts next token 43\n",
    "            # Input 43 → embedding → predicts next token 58\n",
    "            # Input 58 → embedding → predicts next token 5\n",
    "            # … and so on\n",
    "            # ✅ So yes, each step is independent in terms of what embedding is used: only the current token’s embedding is fed into the model to predict the next token.\n",
    "                        \n",
    "        return logits, loss \n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx) # goes to forward function\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C) # pick out only the last element of a B x T  x C logit a  (B, C) = (4, 65) tensor if input is 4 x 8 x 65\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C) # logits to softmax. dim=-1 → apply softmax along the last dimension (here, C, vocab dimension)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1) # get only one\n",
    "            # torch.multinomial samples from a categorical distribution defined by probs\n",
    "            # we want the model’s prediction to guide the choice: tokens with higher probabilities are more likely to be picked.\n",
    "            # probs = [0.7, 0.1, 0.1, 0.1]  # vocab size = 4\n",
    "            # torch.multinomial(probs, 1)   # 70% chance to pick token 0, 10% chance for 1,2,3\n",
    "            # If you always picked argmax, it would be deterministic. Multinomial allows stochastic sampling, which is important for generating diverse tex\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1) concatenate along seq dimension dim=1 → new idx is (B, T+1) = (4, 9)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb) # a forward pass with 4 x 8 matrix\n",
    "# tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
    "#         [44, 53, 56,  1, 58, 46, 39, 58],\n",
    "#         [52, 58,  1, 58, 46, 39, 58,  1],\n",
    "#         [25, 17, 27, 10,  0, 21,  1, 54]])\n",
    "# targets:\n",
    "# torch.Size([4, 8])\n",
    "# tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
    "#         [53, 56,  1, 58, 46, 39, 58,  1],\n",
    "#         [58,  1, 58, 46, 39, 58,  1, 46],\n",
    "#         [17, 27, 10,  0, 21,  1, 54, 39]])\n",
    "print(loss) # we get scores for torch.Size([4, 8, 65])\n",
    "idx = torch.zeros((1,1), dtype=torch.long) # 0 is a newline character and we start \n",
    "idx = torch.tensor([[5]]) # 5 as the starting\n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))\n",
    "# this is without history\n",
    "# bigram model. this looks only at last character to predict next. we expand to use history to predict next token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "39e35ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## training this model\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3) # for smaller network higher LR \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9d627ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6cc088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Step 0, Loss: 4.6973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100, Loss: 4.4980\n",
      "Step 200, Loss: 4.3540\n",
      "Step 300, Loss: 4.3019\n",
      "Step 400, Loss: 4.1383\n",
      "Step 500, Loss: 4.0842\n",
      "Step 600, Loss: 3.9211\n",
      "Step 700, Loss: 3.8928\n",
      "Step 800, Loss: 3.7173\n",
      "Step 900, Loss: 3.6722\n",
      "Step 1000, Loss: 3.5917\n",
      "Step 1100, Loss: 3.4900\n",
      "Step 1200, Loss: 3.4401\n",
      "Step 1300, Loss: 3.3894\n",
      "Step 1400, Loss: 3.3141\n",
      "Step 1500, Loss: 3.2329\n",
      "Step 1600, Loss: 3.1788\n",
      "Step 1700, Loss: 3.1531\n",
      "Step 1800, Loss: 3.0930\n",
      "Step 1900, Loss: 3.0790\n",
      "Step 2000, Loss: 2.9576\n",
      "Step 2100, Loss: 2.9700\n",
      "Step 2200, Loss: 2.8952\n",
      "Step 2300, Loss: 2.8947\n",
      "Step 2400, Loss: 2.8516\n",
      "Step 2500, Loss: 2.8409\n",
      "Step 2600, Loss: 2.8163\n",
      "Step 2700, Loss: 2.6917\n",
      "Step 2800, Loss: 2.7242\n",
      "Step 2900, Loss: 2.6964\n",
      "Step 3000, Loss: 2.6581\n",
      "Step 3100, Loss: 2.6654\n",
      "Step 3200, Loss: 2.6539\n",
      "Step 3300, Loss: 2.6368\n",
      "Step 3400, Loss: 2.6182\n",
      "Step 3500, Loss: 2.5721\n",
      "Step 3600, Loss: 2.5843\n",
      "Step 3700, Loss: 2.5734\n",
      "Step 3800, Loss: 2.5613\n",
      "Step 3900, Loss: 2.5380\n",
      "Step 4000, Loss: 2.6231\n",
      "Step 4100, Loss: 2.5287\n",
      "Step 4200, Loss: 2.5319\n",
      "Step 4300, Loss: 2.5195\n",
      "Step 4400, Loss: 2.5604\n",
      "Step 4500, Loss: 2.5326\n",
      "Step 4600, Loss: 2.4741\n",
      "Step 4700, Loss: 2.5485\n",
      "Step 4800, Loss: 2.4712\n",
      "Step 4900, Loss: 2.5541\n",
      "Step 5000, Loss: 2.5570\n",
      "Step 5100, Loss: 2.4498\n",
      "Step 5200, Loss: 2.4292\n",
      "Step 5300, Loss: 2.5185\n",
      "Step 5400, Loss: 2.5089\n",
      "Step 5500, Loss: 2.4749\n",
      "Step 5600, Loss: 2.4744\n",
      "Step 5700, Loss: 2.4473\n",
      "Step 5800, Loss: 2.5302\n",
      "Step 5900, Loss: 2.4910\n",
      "Step 6000, Loss: 2.4719\n",
      "Step 6100, Loss: 2.4853\n",
      "Step 6200, Loss: 2.4663\n",
      "Step 6300, Loss: 2.5173\n",
      "Step 6400, Loss: 2.5146\n",
      "Step 6500, Loss: 2.5033\n",
      "Step 6600, Loss: 2.4728\n",
      "Step 6700, Loss: 2.4705\n",
      "Step 6800, Loss: 2.4663\n",
      "Step 6900, Loss: 2.4200\n",
      "Step 7000, Loss: 2.5491\n",
      "Step 7100, Loss: 2.4753\n",
      "Step 7200, Loss: 2.4992\n",
      "Step 7300, Loss: 2.4683\n",
      "Step 7400, Loss: 2.4332\n",
      "Step 7500, Loss: 2.4912\n",
      "Step 7600, Loss: 2.4577\n",
      "Step 7700, Loss: 2.4696\n",
      "Step 7800, Loss: 2.4468\n",
      "Step 7900, Loss: 2.4483\n",
      "Step 8000, Loss: 2.4880\n",
      "Step 8100, Loss: 2.4846\n",
      "Step 8200, Loss: 2.4700\n",
      "Step 8300, Loss: 2.4772\n",
      "Step 8400, Loss: 2.4981\n",
      "Step 8500, Loss: 2.4946\n",
      "Step 8600, Loss: 2.4077\n",
      "Step 8700, Loss: 2.4934\n",
      "Step 8800, Loss: 2.4601\n",
      "Step 8900, Loss: 2.3890\n",
      "Step 9000, Loss: 2.4998\n",
      "Step 9100, Loss: 2.4722\n",
      "Step 9200, Loss: 2.4444\n",
      "Step 9300, Loss: 2.4683\n",
      "Step 9400, Loss: 2.4258\n",
      "Step 9500, Loss: 2.4387\n",
      "Step 9600, Loss: 2.4567\n",
      "Step 9700, Loss: 2.4587\n",
      "Step 9800, Loss: 2.4349\n",
      "Step 9900, Loss: 2.4142\n",
      "Training finished in 140.34 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Move model to GPU\n",
    "m = m.to(device)\n",
    "\n",
    "batch_size = 128  # bigger batch helps GPU utilization\n",
    "steps = 10000\n",
    "\n",
    "# Optional: wrap get_batch to move to GPU automatically\n",
    "def get_batch_device(split):\n",
    "    xb, yb = get_batch(split)\n",
    "    return xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
    "\n",
    "start_time = time.time()\n",
    "for step in range(steps):\n",
    "    xb, yb = get_batch_device('train')\n",
    "\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        # print occasionally to avoid slowing down GPU\n",
    "        print(f\"Step {step}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training finished in {end_time - start_time:.2f} seconds\")\n",
    "# 2 min 34 secs for cuda 4.6973 to 2.4142. 2 min 20.3 secs in CPU 4.6973 to 2.4142\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c3836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I yome k ee mprop ves.\n",
      "med belenk s w me ave hirmin, baveard.\n",
      "bellfushealmiere ENus\n",
      "BAy he,\n",
      "NARWhan \n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx=torch.zeros((1,1),dtype=torch.long), max_new_tokens=100)[0].tolist()))\n",
    "#initially the output is \n",
    "# 'XAQHukRuaRJKXAYtXzfJ:HEPiu--sDioi;ILCo3pHNTmDwJsfheKRxZCFs\n",
    "# lZJ XQc?:s:HEzEnXalEPklcPU cL'DpdLCafBheH\n",
    "\n",
    "# after 10000 steps it is \n",
    "# I yome k ee mprop ves.\n",
    "# med belenk s w me ave hirmin, baveard.\n",
    "# bellfushealmiere ENus\n",
    "# BAy he,\n",
    "# NARWhan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1425519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "# # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# m = m.to(device)\n",
    "# for steps in range(10000):\n",
    "#     # sample a batch\n",
    "#     xb, yb = get_batch('train')\n",
    "#     xb = xb.to(device)\n",
    "#     yb = yb.to(device)\n",
    "#     # training loop\n",
    "#     logits, loss = m(xb, yb)\n",
    "#     optimizer.zero_grad(set_to_none=True) # zeroing up the gradients in previous step\n",
    "#     loss.backward()\n",
    "#     optimizer.step() # update parameters\n",
    "#     print(loss.item())\n",
    "# # loss goes from for 3.32 to 3.27 in 100 iterations\n",
    "# # 10,000 steps need 1 min 7.5 seconds in CPU. with cuda it is 1 min 11.2 secs for 10,000 from start. loss went from 4.67 to 2.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "72741e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tokens are not taking to each other. now they talk to each other and figure out what is in context and predict better\n",
    "# estimate loss in multiple batches - trainand validation loss. torch.no_grad() in estimate loss\n",
    "# token in 5th location should talk only to 1,2,3,4 and not 6,7,8\n",
    "# 5th token - 1,2,3,4 averaged out info like a feature. every t tokens calculate avg of vectors\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7d0b9ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B): # for each  batch\n",
    "    for t in range(T): # for each block from first to cumulative of last \n",
    "        xprev = x[b,:t+1] # (t,C) always a t+1 x c where t ranges from 0 to some number \n",
    "        xbow[b,t] = torch.mean(xprev, 0) # torch.mean(xprev, 0) computes the mean along the first dimension (rows). It sums up each column of xprev (element-wise across the 4 rows).\n",
    "        #Then divides by the number of rows (t+1 = 4) → gives average per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4319ca70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.3596, -0.9152],\n",
      "        [ 0.6258,  0.0255],\n",
      "        [ 0.9545,  0.0643],\n",
      "        [ 0.3612,  1.1679],\n",
      "        [-1.3499, -0.5102],\n",
      "        [ 0.2360, -0.2398],\n",
      "        [-0.9211,  1.5433]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n"
     ]
    }
   ],
   "source": [
    "print(x[0])\n",
    "print(xbow[0])\n",
    "# tensor([[ 0.1808, -0.0700],\n",
    "#         [-0.3596, -0.9152],\n",
    "#         [ 0.6258,  0.0255],\n",
    "#         [ 0.9545,  0.0643],\n",
    "#         [ 0.3612,  1.1679],\n",
    "#         [-1.3499, -0.5102],\n",
    "#         [ 0.2360, -0.2398],\n",
    "#         [-0.9211,  1.5433]])\n",
    "# tensor([[ 0.1808, -0.0700],\n",
    "#         [-0.0894, -0.4926],\n",
    "#         [ 0.1490, -0.3199],\n",
    "#         [ 0.3504, -0.2238],\n",
    "#         [ 0.3525,  0.0545],\n",
    "#         [ 0.0688, -0.0396],\n",
    "#         [ 0.0927, -0.0682],\n",
    "#         [-0.0341,  0.1332]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7bcc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "# torch.ones give 3 x 3 of 1 s\n",
    "# troch.tril gives a lower quadrant 1s and upper zeros\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "# this gives the avg of each row in place of 1s, first row has one 1 so it is 1, second row has two 1s so 0.5 , 0.5 each row adds up to 1. so in this way our matrix \n",
    "# multiplication gives avg till that number , basically what we did using for loop above\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9837db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 2: using matrix multiply for a weighted aggregation\n",
    "wei = torch.tril(torch.ones(T, T)) # using the above concept we get T x T - each row\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C). Torch auto adds B times T x T to wei \n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382456c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 3: use Softmax\n",
    "# weighted aggregation of lower triangle. the -inf mask is to ensure future tokens are not communicating with past when we do weighted average\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
